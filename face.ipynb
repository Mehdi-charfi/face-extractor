{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBjwQAeL7bwpammlEXDQDT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehdi-charfi/face-extractor/blob/master/face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dlib\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "import shutil"
      ],
      "metadata": {
        "id": "G5ViNSmYP2TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained models for face and upper body detection\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "upper_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n"
      ],
      "metadata": {
        "id": "IyOh4-wFQS42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained feature extraction models (e.g., ResNet50)\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "face_feature_extractor = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "face_feature_extractor.fc = nn.Identity()  # Remove the final classification layer\n",
        "face_feature_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "upper_body_feature_extractor = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "upper_body_feature_extractor.fc = nn.Identity()  # Remove the final classification layer\n",
        "upper_body_feature_extractor.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "id": "a2Tt59R2QV_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define image preprocessing function\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    image = np.transpose(image, (2, 0, 1))  # Convert HWC to CHW format\n",
        "    return torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to detect, resize, and save faces and upper bodies, and return their embeddings\n",
        "def detect_and_extract_embeddings(image_path, save_crops=False, output_dir=\"detected_crops\", crop_size=(128, 128)):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces and upper bodies\n",
        "    faces = face_detector(gray)\n",
        "    upper_bodies = upper_body_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(60, 60))\n",
        "\n",
        "    # Create output directory if saving crops\n",
        "    if save_crops and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    embeddings = []\n",
        "       # Process faces\n",
        "    for idx, face in enumerate(faces):\n",
        "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
        "        face_crop = image[y:y+h, x:x+w]\n",
        "        face_resized = cv2.resize(face_crop, crop_size)\n",
        "\n",
        "        # Save face crop if required\n",
        "        if save_crops:\n",
        "            face_filename = os.path.join(output_dir, f\"face_{os.path.basename(image_path).split('.')[0]}_{idx}.png\")\n",
        "            cv2.imwrite(face_filename, face_resized)\n",
        "\n",
        "        # Extract face embeddings\n",
        "        face_tensor = preprocess_image(face_resized)\n",
        "        with torch.no_grad():\n",
        "            face_embedding = face_feature_extractor(face_tensor).squeeze().numpy()\n",
        "        embeddings.append((face_embedding, \"face\", face_filename if save_crops else image_path))\n",
        "\n",
        "    # Process upper bodies\n",
        "    for idx, (x, y, w, h) in enumerate(upper_bodies):\n",
        "        upper_body_crop = image[y:y+h, x:x+w]\n",
        "        upper_body_resized = cv2.resize(upper_body_crop, crop_size)\n",
        "\n",
        "        # Save upper body crop if required\n",
        "        if save_crops:\n",
        "            upper_body_filename = os.path.join(output_dir, f\"upper_body_{os.path.basename(image_path).split('.')[0]}_{idx}.png\")\n",
        "            cv2.imwrite(upper_body_filename, upper_body_resized)\n",
        "\n",
        "        # Extract upper body embeddings\n",
        "        upper_body_tensor = preprocess_image(upper_body_resized)\n",
        "        with torch.no_grad():\n",
        "            upper_body_embedding = upper_body_feature_extractor(upper_body_tensor).squeeze().numpy()\n",
        "        embeddings.append((upper_body_embedding, \"upper_body\", upper_body_filename if save_crops else image_path))\n",
        "\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "V8MxZ5c3QdhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define data augmentation pipeline\n",
        "augmentation_pipeline = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define custom dataset class\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, image_path\n",
        "\n",
        "# Custom collate function to handle batch issues\n",
        "def custom_collate_fn(batch):\n",
        "    images, paths = zip(*batch)\n",
        "    return list(images), list(paths)\n",
        "\n",
        "# Function to load image paths from a directory\n",
        "def load_image_paths(directory):\n",
        "    return [os.path.join(directory, filename) for filename in os.listdir(directory) if filename.lower().endswith(('png', 'jpg', 'jpeg'))]\n"
      ],
      "metadata": {
        "id": "jDqF_ucFQl_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to find the optimal number of clusters using the silhouette score\n",
        "def find_optimal_clusters(embeddings):\n",
        "    best_num_clusters = 2\n",
        "    best_score = -1\n",
        "    for num_clusters in range(2, min(11, len(embeddings))):  # Limit to 10 or fewer clusters for efficiency\n",
        "        clustering_model = AgglomerativeClustering(n_clusters=num_clusters)\n",
        "        labels = clustering_model.fit_predict(embeddings)\n",
        "        score = silhouette_score(embeddings, labels)\n",
        "        if score > best_score:\n",
        "            best_num_clusters = num_clusters\n",
        "            best_score = score\n",
        "    return best_num_clusters\n",
        "\n",
        "# Function to cluster embeddings and save images in classified folders\n",
        "def cluster_embeddings(embeddings_with_filenames, output_dir=\"classified_crops\"):\n",
        "    embeddings = [embedding for embedding, _, _ in embeddings_with_filenames]\n",
        "    optimal_clusters = find_optimal_clusters(embeddings)\n",
        "    clustering_model = AgglomerativeClustering(n_clusters=optimal_clusters)\n",
        "    labels = clustering_model.fit_predict(embeddings)\n",
        "\n",
        "    # Create output directories for each cluster\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for cluster_idx in range(optimal_clusters):\n",
        "        cluster_dir = os.path.join(output_dir, f\"cluster_{cluster_idx}\")\n",
        "        if not os.path.exists(cluster_dir):\n",
        "            os.makedirs(cluster_dir)\n",
        "\n",
        "    # Save images to respective cluster folders\n",
        "    for (_, crop_type, filename), label in zip(embeddings_with_filenames, labels):\n",
        "        shutil.copy(filename, os.path.join(output_dir, f\"cluster_{label}\", f\"{crop_type}_{os.path.basename(filename)}\"))\n",
        "\n",
        "    return labels\n",
        "\n"
      ],
      "metadata": {
        "id": "kFaAApKSQ6ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoWvrCHxHoJx",
        "outputId": "b7feb3f5-e038-4b35-f3c0-ce20dc0fe143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering complete! Faces and upper bodies have been classified and saved in respective cluster folders.\n"
          ]
        }
      ],
      "source": [
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to your image directory\n",
        "    image_directory = \"imgs\"\n",
        "\n",
        "    # Load image paths\n",
        "    image_paths = load_image_paths(image_directory)\n",
        "\n",
        "    # Create dataset and data loader\n",
        "    image_dataset = CustomImageDataset(image_paths=image_paths, transform=augmentation_pipeline)\n",
        "    data_loader = DataLoader(image_dataset, batch_size=32, shuffle=True, num_workers=3, collate_fn=custom_collate_fn)  # Reduced num_workers for system compatibility\n",
        "\n",
        "    # Collect features and filenames for clustering\n",
        "    all_embeddings_with_filenames = []\n",
        "\n",
        "    # Iterate over batches and process\n",
        "    for batch, paths in data_loader:\n",
        "        for i, path in enumerate(paths):\n",
        "            embeddings = detect_and_extract_embeddings(path, save_crops=True)\n",
        "            all_embeddings_with_filenames.extend(embeddings)\n",
        "\n",
        "    # Perform clustering on the collected embeddings\n",
        "    labels = cluster_embeddings(all_embeddings_with_filenames)\n",
        "\n",
        "    # Print clustering results\n",
        "    print(\"Clustering complete! Faces and upper bodies have been classified and saved in respective cluster folders.\")\n"
      ]
    }
  ]
}